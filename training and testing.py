# -*- coding: utf-8 -*-
"""Copy of MP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NX7EhBZyn4c3gIHeFUuIbuv86XQFgXFO
"""

import os
count=0;
import cv2

from google.colab import drive
drive.mount('/content/drive')

!pip install gitpython
import git
git.Repo.clone_from('https://github.com/seymanurakti/fight-detection-surv-dataset', '/content/drive/MyDrive/parkavi')

for filename in os.listdir('/content/drive/MyDrive/parkavi/fight'):
  #print(filename)
  vidObj = cv2.VideoCapture('/content/drive/MyDrive/parkavi/fight/'+filename)
  while True:
        success, image = vidObj.read()
        #print(success)
        # Saves the frames with frame-count
        if success:
          cv2.resize(image,(240,240));
          cv2.imwrite("/content/drive/MyDrive/parkavi/Dataset/fight1/frame%d.jpg" % count, image)
          count += 1
        else:
          break
  vidObj.release()
  cv2.destroyAllWindows()

count=0

for filename in os.listdir('/content/drive/MyDrive/parkavi/noFight'):
  #print(filename)
  vidObj = cv2.VideoCapture('/content/drive/MyDrive/parkavi/noFight/'+filename)
  while True:
        success, image = vidObj.read()
        #print(success)
        # Saves the frames with frame-count
        if success:
          cv2.resize(image,(240,240));
          cv2.imwrite("/content/drive/MyDrive/parkavi/Dataset/nonfight1/frame%d.jpg" % count, image)
          count += 1
        else:
          break
  vidObj.release()
  cv2.destroyAllWindows()

from keras.applications.inception_v3 import InceptionV3
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping
#from data import DataSet
import os.path

import tensorflow as tf
from keras import backend as K

# Check GPU availability
print("GPU Available:", tf.test.is_gpu_available())

# Configure Keras to use the GPU
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.Session(config=config)
K.set_session(session)

# Rest of your Keras code that utilizes GPU

def get_model(weights='imagenet'):
    # create the base pre-trained model
    base_model = InceptionV3(weights=weights, include_top=False)

    # add a global spatial average pooling layer
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    # let's add a fully-connected layer
    x = Dense(1024, activation='relu')(x)
    # and a logistic layer
    predictions = Dense(2, activation='softmax')(x)

    # this is the model we will train
    model = Model(inputs=base_model.input, outputs=predictions)
    return model

import shutil

location="/content/drive/MyDrive/parkavi/Dataset"
path = os.path.join(location, '.ipynb_checkpoints')
print(path)
# removing directory
shutil.rmtree(path)

def get_generators():
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        horizontal_flip=True,
        rotation_range=10.,
        width_shift_range=0.2,
        height_shift_range=0.2)

    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        '/content/drive/MyDrive/parkavi/Dataset/',
        target_size=(299, 299),
        batch_size=32,
        class_mode='categorical')

    validation_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/parkavi/Dataset/',
        target_size=(299, 299),
        batch_size=32,
        class_mode='categorical')

    return train_generator, validation_generator

model = get_model()
generators = get_generators()

checkpointer = ModelCheckpoint(
    filepath=os.path.join('data', 'checkpoints', 'inception.{epoch:03d}.hdf5'),
    verbose=1,
    save_best_only=True)

# Helper: Stop when we stop learning.
early_stopper = EarlyStopping(patience=10)

# Helper: TensorBoard
tensorboard = TensorBoard(log_dir=os.path.join('data', 'logs'))

def train_model(model, nb_epoch, generators, callbacks=[]):
    train_generator =generators
    model.fit_generator(
        train_generator,
        steps_per_epoch=100,
        epochs=nb_epoch,
        callbacks=callbacks)
    return model

def freeze_all_but_top(model):
    """Used to train just the top layers of the model."""
    # first: train only the top layers (which were randomly initialized)
    # i.e. freeze all convolutional InceptionV3 layers
    for layer in model.layers[:-2]:
        layer.trainable = False

    # compile the model (should be done *after* setting layers to non-trainable)
    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

    return model

def freeze_all_but_mid_and_top(model):
    """After we fine-tune the dense layers, train deeper."""
    # we chose to train the top 2 inception blocks, i.e. we will freeze
    # the first 172 layers and unfreeze the rest:
    for layer in model.layers[:172]:
        layer.trainable = False
    for layer in model.layers[172:]:
        layer.trainable = True

    # we need to recompile the model for these modifications to take effect
    # we use SGD with a low learning rate
    model.compile(
        optimizer=SGD(lr=0.0001, momentum=0.9),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_k_categorical_accuracy'])

    return model

train_generator, validation_generator = get_generators()  # Separate generators for training and validation data

model = get_model()
model = freeze_all_but_top(model)
model = train_model(model, 10,train_generator,
                        [checkpointer, early_stopper, tensorboard])

os.chdir('/content/drive/MyDrive/parkavi')

model.save('model1.h5')

for file in os.listdir('/content/drive/MyDrive/parkavi/Dataset'):
    print('/content/drive/MyDrive/parkavi/Dataset/'+file)

model = freeze_all_but_mid_and_top(model)
model = train_model(model, 10,train_generator,
                        [checkpointer, early_stopper, tensorboard])

model.save('model2.h5')

import matplotlib.pyplot as plt
plt.plot(model.history.history['loss'])

plt.plot(model.history.history['accuracy'])

count=0
#for filename in os.listdir('/content/fight-detection-surv-dataset/noFight'):
  #print(filename)
vidObj = cv2.VideoCapture('/content/drive/MyDrive/parkavi/fight/fi008.mp4')
print(vidObj)
while True:
        success, image = vidObj.read()
        #print(success)
        # Saves the frames with frame-count
        if success:
          cv2.resize(image,(299,299));
          cv2.imwrite("/content/drive/MyDrive/parkavi/tf/frame%d.jpg" % count, image)
          count += 1
        else:
          break
vidObj.release()
cv2.destroyAllWindows()

count=0
#for filename in os.listdir('/content/fight-detection-surv-dataset/noFight'):
  #print(filename)
vidObj = cv2.VideoCapture('/content/drive/MyDrive/parkavi/noFight/nofi008.mp4')
print(vidObj)
while True:
        success, image = vidObj.read()
        #print(success)
        # Saves the frames with frame-count
        if success:
          cv2.resize(image,(299,299));
          cv2.imwrite("/content/drive/MyDrive/parkavi/tnf/frame%d.jpg" % count, image)
          count += 1
        else:
          break
vidObj.release()
cv2.destroyAllWindows()

import numpy as np

from keras.models import load_model

# Load the model
model = load_model('/content/drive/MyDrive/parkavi/model2.h5')

import cv2,os

import cv2
import matplotlib.pyplot as plt
from IPython.display import display, HTML

# Load the video file
video_path = '/content/drive/MyDrive/parkavi/noFight/nofi007.mp4'
video = cv2.VideoCapture(video_path)

# Create a function to preprocess the frame
def preprocess(frame):
    # Resize the frame if needed
    # processed_frame = cv2.resize(frame, (width, height))

    # Preprocess the frame (e.g., resize, normalize, etc.)
    resized_frame = cv2.resize(frame, (224, 224))
    normalized_frame = resized_frame / 255.0
    input_frame = normalized_frame.reshape(1, 224, 224, 3)
    return input_frame

# Create a function to process and display the video
def process_video(video):
    while video.isOpened():
        ret, frame = video.read()
        if not ret:
            break
        # Preprocess the frame
        processed_frame = preprocess(frame)

        # Make a prediction on the processed frame
        prediction = model.predict(processed_frame)

        # Determine the class label based on the prediction
        print(prediction)
        if prediction[0][0]>0.5:
            label = 'Fighting recorded'
        else:
            label = 'No fight'

        # Overlay the label on the frame
        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # Display the frame
        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.show()

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the video object
    video.release()
    cv2.destroyAllWindows()

# Process and display the video
process_video(video)

import cv2
import matplotlib.pyplot as plt

# Load the video file
#video_path = '/content/drive/MyDrive/parkavi/fight/fi002.mp4'
video_path = '/content/drive/MyDrive/parkavi/V2.mp4'

video = cv2.VideoCapture(video_path)

# Create a function to preprocess the frame
def preprocess(frame):
    # Resize the frame if needed
    # processed_frame = cv2.resize(frame, (width, height))

    # Preprocess the frame (e.g., resize, normalize, etc.)
    resized_frame = cv2.resize(frame, (224, 224))
    normalized_frame = resized_frame / 255.0
    input_frame = normalized_frame.reshape(1, 224, 224, 3)
    return input_frame

# Create a function to process and display the video
def process_video(video):
    fig, ax = plt.subplots()
    plt.axis('off')  # Turn off axes
    plt.tight_layout()  # Ensure tight layout

    while video.isOpened():
        ret, frame = video.read()
        if not ret:
            break
        # Preprocess the frame
        processed_frame = preprocess(frame)

        # Make a prediction on the processed frame
        prediction = model.predict(processed_frame, verbose=0)

        # Determine the class label based on the prediction
        if prediction[0][0] >= 0.5:
            label = 'Fighting recorded'
        else:
            label = 'No fight'

        # Overlay the label on the frame
        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB
        ax.text(10, 30, label, color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))

        # Update the plot
        plt.pause(0.001)
        plt.show()  # Display the plot

        # Clear the previous frame
        ax.cla()

    # Release the video object
    video.release()
    plt.close(fig)  # Close the figure to avoid multiple plots

# Process and display the video
process_video(video)

count=0
#for filename in os.listdir('/content/fight-detection-surv-dataset/noFight'):
  #print(filename)
vidObj = cv2.VideoCapture('/content/drive/MyDrive/parkavi/V7.mp4')
print(vidObj)
while True:
        success, image = vidObj.read()
        #print(success)
        # Saves the frames with frame-count
        if success:
          cv2.resize(image,(299,299));
          cv2.imwrite("/content/drive/MyDrive/parkavi/t/frame%d.jpg" % count, image)
          count += 1
        else:
          break
vidObj.release()
cv2.destroyAllWindows()

for image1 in os.listdir('/content/drive/MyDrive/parkavi/t'):
  image = cv2.imread(os.path.join('/content/drive/MyDrive/parkavi/t',image1))
  if image is not None:
      #x = image.img_to_array(img)
      x = np.expand_dims(image, axis=0)

      images = np.vstack([x])
      classes = model.predict(images, batch_size=10)
      print(classes[0])
      if classes[0][1]<=0:
          print("Fighting recorded")
      else:
          print("No fight")

for image1 in os.listdir('/content/drive/MyDrive/parkavi/tf'):
  image = cv2.imread(os.path.join('/content/drive/MyDrive/parkavi/tf',image1))
  if image is not None:
      #x = image.img_to_array(img)
      x = np.expand_dims(image, axis=0)

      images = np.vstack([x])
      classes = model.predict(images, batch_size=10)
      print(classes[0])
      if classes[0][1]<=0:
          print("Fighting recorded")
      else:
          print("No fight")

for image1 in os.listdir('/content/drive/MyDrive/parkavi/tnf'):
  image = cv2.imread(os.path.join('/content/drive/MyDrive/parkavi/tnf',image1))
  if image is not None:
      #x = image.img_to_array(img)
      x = np.expand_dims(image, axis=0)

      images = np.vstack([x])
      classes = model.predict(images, batch_size=10)
      print(classes[0])
      if classes[0][1]<=0:
          print("Fighting recorded")
      else:

          print("No fight")